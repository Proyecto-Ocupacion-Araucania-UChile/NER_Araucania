{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpacyNER_Araucania_BETO(local_env).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Introduction\n",
        "\n",
        "\n",
        "In this tutorial, we will refine a transformation model for *Named Entity Recognition* based on the BETO model (a Spanish adaptation of the BERT model). \n",
        "This tutorial aims at producing a tranformers model via the spacy and sklearn library by proceeding to the cross validation technique.\n",
        "\n",
        "**Warning** : This processing chain works only via the notebook interface (when using the GPU colab). It is possible to use the native *subsystem* library to execute bash commands."
      ],
      "metadata": {
        "id": "Qyjc2RsZ4wXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Configuration tu run colab in local environnement**\n",
        "- Step 1: Install Jupyter\n",
        "\n",
        "Install Jupyter on your local machine.\n",
        "- Step 2: Install the jupyter_http_over_ws extension and activate it (one time only)\n",
        "\n",
        "Created by the Colaboratory team, the jupyter_http_over_ws extension is available on GitHub.\n",
        "\n",
        "`pip install jupyter_http_over_ws jupyter serverextension enable --py jupyter_http_over_ws`\n",
        "\n",
        "- Step 3: Start the server and perform authentication\n",
        "\n",
        "Even if the new notebook servers are started normally, you must set a flag to clearly approve WebSocket connections from the Colaboratory interface.\n",
        "\n",
        "`jupyter notebook \\\n",
        "  --NotebookApp.allow_origin='https://colab.research.google.com' \\\n",
        "  --port=8888 \\\n",
        "  --NotebookApp.port_retries=0`\n",
        "    \n",
        "\n",
        "After starting, the server will display a message containing the initial backend URL used for authentication. Copy this URL, as you will need it in the next step.\n",
        "- Step 4: Connect to the local runtime environment\n",
        "\n",
        "In Colaboratory, click on the \"Connect\" button, and then select \"Connect to a local runtime environment\". In the dialog box that appears, enter the URL you copied in the previous step and click the \"Connect\" button. Now you should be connected to your local execution environment. "
      ],
      "metadata": {
        "id": "IPGiJwERl2qx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Flow of the notebook\n",
        "\n",
        "The notebook will be divided into seperate sections to provide a organized walk through for the process used.\n",
        "\n",
        "1. [Checking system and requirements](#section00)\n",
        "2. [Configuration system](#section01)\n",
        "3. [Finetuning](#section02) \\\n",
        "3-1. [Preprocessing](#section021) \\\n",
        "3-2. [Training](#section022)\n",
        "4. [Global evaluation](#section03)"
      ],
      "metadata": {
        "id": "wtDoCtIqA23h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section00\"></a>\n",
        "####Checking"
      ],
      "metadata": {
        "id": "LainhQPbPiWb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3JC4YNX-Gil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9220a4ed-dad7-4760-bcf8-be18c8a77513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jul 24 01:42:22 2022       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 515.57       Driver Version: 516.59       CUDA Version: 11.7     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                               |                      |               MIG M. |\r\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  On   | 00000000:07:00.0  On |                  N/A |\n",
            "|  0%   45C    P8    29W / 370W |    648MiB / 10240MiB |     37%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#Check gpu activity\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### install dependencies"
      ],
      "metadata": {
        "id": "7dVR7p4dQcom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pandas\n",
        "!pip install -U scikit-learn\n",
        "#To use your GPU in local you need to install the CUPY version CUDA of your system\n",
        "#https://github.com/explosion/spacy-transformers\n",
        "!pip install -U spacy[transformers,cuda117]"
      ],
      "metadata": {
        "id": "lCApoHl0-Lu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc2e69a-b465-4de6-df23-1951e58345e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already up-to-date: pandas in ./.env/lib/python3.8/site-packages (1.4.3)\r\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.8.1 in ./.env/lib/python3.8/site-packages (from pandas) (2.8.2)\r\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in ./.env/lib/python3.8/site-packages (from pandas) (1.23.1)\r\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2020.1 in ./.env/lib/python3.8/site-packages (from pandas) (2022.1)\r\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in ./.env/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already up-to-date: scikit-learn in ./.env/lib/python3.8/site-packages (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in ./.env/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=1.3.2 in ./.env/lib/python3.8/site-packages (from scikit-learn) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in ./.env/lib/python3.8/site-packages (from scikit-learn) (1.23.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=1.0.0 in ./.env/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already up-to-date: spacy[cuda117,transformers] in ./.env/lib/python3.8/site-packages (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<2.1.0,>=2.0.6 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (2.0.7)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (44.0.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (21.3)\n",
            "Requirement already satisfied, skipping upgrade: langcodes<4.0.0,>=3.2.0 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (1.0.7)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (4.64.0)\n",
            "Requirement already satisfied, skipping upgrade: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (1.9.1)\n",
            "Requirement already satisfied, skipping upgrade: thinc<8.2.0,>=8.1.0 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (8.1.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (2.28.1)\n",
            "Requirement already satisfied, skipping upgrade: typer<0.5.0,>=0.3.0 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (3.1.2)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (2.0.6)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.9.1 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (0.9.1)\n",
            "Requirement already satisfied, skipping upgrade: srsly<3.0.0,>=2.4.3 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (2.4.4)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (3.0.6)\n",
            "Requirement already satisfied, skipping upgrade: spacy-legacy<3.1.0,>=3.0.9 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (3.0.9)\n",
            "Requirement already satisfied, skipping upgrade: spacy-loggers<2.0.0,>=1.0.0 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (1.0.3)\n",
            "Requirement already satisfied, skipping upgrade: pathy>=0.3.5 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (0.6.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (1.23.1)\n",
            "Collecting cupy-cuda117<11.0.0,>=5.0.0b4; extra == \"cuda117\"\n",
            "  Using cached cupy_cuda117-10.6.0-cp38-cp38-manylinux1_x86_64.whl (83.5 MB)\n",
            "Requirement already satisfied, skipping upgrade: spacy-transformers<1.2.0,>=1.1.2; extra == \"transformers\" in ./.env/lib/python3.8/site-packages (from spacy[cuda117,transformers]) (1.1.7)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=3.0.5,>=2.0.2 in ./.env/lib/python3.8/site-packages (from packaging>=20.0->spacy[cuda117,transformers]) (3.0.9)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4.3 in ./.env/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy[cuda117,transformers]) (4.3.0)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.7.8 in ./.env/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.0->spacy[cuda117,transformers]) (0.7.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in ./.env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda117,transformers]) (1.26.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in ./.env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda117,transformers]) (2022.6.15)\n",
            "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in ./.env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda117,transformers]) (3.3)\n",
            "Requirement already satisfied, skipping upgrade: charset-normalizer<3,>=2 in ./.env/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy[cuda117,transformers]) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: click<9.0.0,>=7.1.1 in ./.env/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy[cuda117,transformers]) (8.1.3)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.0 in ./.env/lib/python3.8/site-packages (from jinja2->spacy[cuda117,transformers]) (2.1.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open<6.0.0,>=5.2.1 in ./.env/lib/python3.8/site-packages (from pathy>=0.3.5->spacy[cuda117,transformers]) (5.2.1)\n",
            "Collecting fastrlock>=0.5\n",
            "  Using cached fastrlock-0.8-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (49 kB)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in ./.env/lib/python3.8/site-packages (from spacy-transformers<1.2.0,>=1.1.2; extra == \"transformers\"->spacy[cuda117,transformers]) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: spacy-alignments<1.0.0,>=0.7.2 in ./.env/lib/python3.8/site-packages (from spacy-transformers<1.2.0,>=1.1.2; extra == \"transformers\"->spacy[cuda117,transformers]) (0.8.5)\n",
            "Requirement already satisfied, skipping upgrade: transformers<4.21.0,>=3.4.0 in ./.env/lib/python3.8/site-packages (from spacy-transformers<1.2.0,>=1.1.2; extra == \"transformers\"->spacy[cuda117,transformers]) (4.20.1)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers!=0.11.3,<0.13,>=0.11.1 in ./.env/lib/python3.8/site-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2; extra == \"transformers\"->spacy[cuda117,transformers]) (0.12.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in ./.env/lib/python3.8/site-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2; extra == \"transformers\"->spacy[cuda117,transformers]) (6.0)\n",
            "Requirement already satisfied, skipping upgrade: huggingface-hub<1.0,>=0.1.0 in ./.env/lib/python3.8/site-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2; extra == \"transformers\"->spacy[cuda117,transformers]) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in ./.env/lib/python3.8/site-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2; extra == \"transformers\"->spacy[cuda117,transformers]) (2022.7.9)\n",
            "Requirement already satisfied, skipping upgrade: filelock in ./.env/lib/python3.8/site-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2; extra == \"transformers\"->spacy[cuda117,transformers]) (3.7.1)\n",
            "Installing collected packages: fastrlock, cupy-cuda117\n",
            "Successfully installed cupy-cuda117-10.6.0 fastrlock-0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#If your use a RTX3000, you need to install preview package of pytorch (Here works on = or > CUDA 116)\n",
        "!pip uninstall torch torchvision torchaudio\n",
        "!pip install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cu116"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvT9RhWHUD4w",
        "outputId": "f6cb8d36-f816-4aad-ca26-a0880753a4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/nightly/cu116\r\n",
            "Requirement already satisfied: torch in ./.env/lib/python3.8/site-packages (1.12.0)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu116/torchvision-0.14.0.dev20220723%2Bcu116-cp38-cp38-linux_x86_64.whl (23.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.8 MB 23.6 MB/s \n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cu116/torchaudio-0.13.0.dev20220723%2Bcu116-cp38-cp38-linux_x86_64.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 754 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in ./.env/lib/python3.8/site-packages (from torch) (4.3.0)\n",
            "Requirement already satisfied: numpy in ./.env/lib/python3.8/site-packages (from torchvision) (1.23.1)\n",
            "Requirement already satisfied: requests in ./.env/lib/python3.8/site-packages (from torchvision) (2.28.1)\n",
            "Collecting pillow!=8.3.*,>=5.3.0\n",
            "  Using cached Pillow-9.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in ./.env/lib/python3.8/site-packages (from requests->torchvision) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.env/lib/python3.8/site-packages (from requests->torchvision) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.env/lib/python3.8/site-packages (from requests->torchvision) (1.26.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.env/lib/python3.8/site-packages (from requests->torchvision) (3.3)\n",
            "\u001b[31mERROR: torchvision 0.14.0.dev20220723+cu116 has requirement torch==1.13.0.dev20220723+cu116, but you'll have torch 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchaudio 0.13.0.dev20220723+cu116 has requirement torch==1.13.0.dev20220723, but you'll have torch 1.12.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pillow, torchvision, torchaudio\n",
            "Successfully installed pillow-9.2.0 torchaudio-0.13.0.dev20220723+cu116 torchvision-0.14.0.dev20220723+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section01\"></a>\n",
        "####Configuration"
      ],
      "metadata": {
        "id": "L0RtQ3GpQktv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for dev and train data\n",
        "import os\n",
        "#specific train\n",
        "if not os.path.isdir('./nlp'):\n",
        "  !mkdir ./nlp\n",
        "#data\n",
        "if not os.path.isdir('./nlp/spacyNER_data'):\n",
        "  !mkdir ./nlp/spacyNER_data\n",
        "#model \n",
        "if not os.path.isdir('./nlp/spacyNER_model'):\n",
        "  !mkdir ./nlp/spacyNER_model\n",
        "#cross_validation\n",
        "if not os.path.isdir('./nlp/spacyNER_model/cross_valid'):\n",
        " !mkdir ./nlp/spacyNER_model/cross_valid"
      ],
      "metadata": {
        "id": "jbXoo5Xs-NZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Checking GPU works"
      ],
      "metadata": {
        "id": "ABccD_-6UcWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp"
      ],
      "metadata": {
        "id": "wp_6xLm8S-bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfbedAwTTSIA",
        "outputId": "c9c685ec-ec97-4d89-d850-d6db95caa273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy.require_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CaDeeL6-O5t",
        "outputId": "419af107-8333-45dd-822c-93d4b90e6328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section02'></a>\n",
        "### Finetuning"
      ],
      "metadata": {
        "id": "l6WEZjlB47nE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section021'></a>\n",
        "####Preprocessing"
      ],
      "metadata": {
        "id": "n02SBdZPQp17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "def split_dataset(dataframe : DataFrame, train_ratio: float):\n",
        "  \"\"\"\n",
        "  function to split dataframe with ration as you want\n",
        "  :dataframe: dataframe\n",
        "  :train_ratio: float, ratio of split training\n",
        "  :return: None\n",
        "  \"\"\"\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  assert(train_ratio < 1), \"the number must be value between 0 and 1\"\n",
        "\n",
        "  train_df, test_df = train_test_split(dataframe, test_size= 1 - train_ratio)\n",
        "  \n",
        "  return train_df, test_df"
      ],
      "metadata": {
        "id": "3D5VUh6r-QjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "def convert_binary(name: str, data: DataFrame):\n",
        "  \"\"\"\n",
        "  function to convert dataset (Dataframe) in binary spacy format\n",
        "  :name: str, name of binary file outpout\n",
        "  :data: dataframe\n",
        "  :return: count of tokens and entities in file\n",
        "  \"\"\"\n",
        "  from spacy.tokens import DocBin\n",
        "  \n",
        "  #Generate tokenization\n",
        "  nlp = spacy.blank(\"es\")\n",
        "  # the DocBin will store the example documents\n",
        "  db = DocBin(attrs=[\"ENT_IOB\", \"ENT_TYPE\"])\n",
        "\n",
        "  #counting variable\n",
        "  n_token = 0\n",
        "  n_entities = 0\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    doc = nlp(row[\"text\"])\n",
        "    n_token += len(doc)\n",
        "    n_entities += len(row[\"label\"])\n",
        "    ents = []\n",
        "    for ent in row[\"label\"]:\n",
        "      start, end, label = tuple(ent)\n",
        "      span = doc.char_span(start, end, label=label)\n",
        "      if span is not None:\n",
        "        ents.append(span)\n",
        "      else:\n",
        "        n_entities -= 1\n",
        "    try:\n",
        "      doc.ents = ents\n",
        "    except TypeError:\n",
        "      print(ents)\n",
        "      pass\n",
        "    db.add(doc)\n",
        "    db.to_disk(f\"./nlp/spacyNER_data/{name}.spacy\")\n",
        "  return n_token, n_entities"
      ],
      "metadata": {
        "id": "rAbRo5h1-R7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_json(data: dict):\n",
        "  \"\"\"\n",
        "  Export json file with metadata's models\n",
        "  \n",
        "  :data: dictionary of metadata\n",
        "  \"\"\"\n",
        "  import json\n",
        "\n",
        "  with open(\"./nlp/spacyNER_model/cross_valid/metadata.json\", \"w\", encoding=\"utf-8\") as json_files:\n",
        "    json.dump(data, json_files, ensure_ascii=False, indent=3)"
      ],
      "metadata": {
        "id": "au96vnz-R0ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section022\"></a>\n",
        "#### Training"
      ],
      "metadata": {
        "id": "gZhBMJ6sQurA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration file\n",
        "config = '/content/drive/MyDrive/nlp/base_config_NoTransformers.cfg' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "G_ot0sOnsOQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "\n",
        "#import dataset\n",
        "df = pd.read_json(\"./nlp/spacyNER_data/dataset_araucania.jsonl\", lines = True, encoding=\"utf-8\")\n",
        "\n",
        "#structure dataset\n",
        "\n",
        "dataset = split_dataset(df, 0.90)\n",
        "\n",
        "X = dataset[0]\n",
        "test_dataset = convert_binary(\"test\", dataset[1])\n",
        "print(\"test: \" + str(test_dataset[0]) + \" tokens, \" + str(test_dataset[1]) + \" entities\")\n",
        "\n",
        "#K-Fold configuration\n",
        "kf = KFold(n_splits=6, shuffle = True, random_state = 2)\n",
        "\n",
        "#variables\n",
        "n = 0\n",
        "results = {}\n",
        "\n",
        "#loop on k\n",
        "for train_index , test_index in kf.split(X):\n",
        "  \n",
        "  #enumeration\n",
        "  n += 1\n",
        "  print(\"<----- run k \" + str(n) + \"----->\")\n",
        "\n",
        "  #path\n",
        "  os.mkdir(f\"./nlp/spacyNER_model/cross_valid/fold_{str(n)}\")\n",
        "  path_ouput = f\"./nlp/spacyNER_model/cross_valid/fold_{str(n)}\"\n",
        "  best_model = f\"./nlp/spacyNER_model/cross_valid/fold_{str(n)}/model-best\"\n",
        "  json_output = f\"./nlp/spacyNER_model/cross_valid/fold_{str(n)}/scores.json\"\n",
        "\n",
        "  #convert in binary format\n",
        "  X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
        "  train_binary = convert_binary(\"train\",X_train)\n",
        "  dev_binary = convert_binary(\"dev\",X_test)\n",
        "\n",
        "  #metadata\n",
        "  results[n] ={\n",
        "                    \"test_data\": [test_dataset[0],test_dataset[1]],\n",
        "                    \"train_data\" : [train_binary[0],train_binary[1]],\n",
        "                    \"dev_data\" : [dev_binary[0],dev_binary[1]]\n",
        "                }\n",
        "\n",
        "  #init config\n",
        "  !python -m spacy init fill-config $config config.cfg\n",
        "\n",
        "  #training\n",
        "  !python -m spacy train config.cfg --paths.train ./nlp/spacyNER_data/train.spacy --paths.dev ./nlp/spacyNER_data/dev.spacy -g 0 --output $path_ouput\n",
        "  \n",
        "  #evaluation\n",
        "  !python -m spacy evaluate $best_model ./nlp/spacyNER_data/test.spacy --output $json_output --gold-preproc --gpu-id 0\n",
        "\n",
        "#export json metadata\n",
        "export_json(results)"
      ],
      "metadata": {
        "id": "FknhDHzR2T2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d43817-bec1-4e7c-dcb3-abfcdaa870c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: 1984 tokens, 174 entities\n",
            "<----- run k 1----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory: nlp/spacyNER_model/cross_valid/fold_1\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-24 01:43:15,615] [INFO] Set up nlp object from config\n",
            "[2022-07-24 01:43:15,622] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-07-24 01:43:15,625] [INFO] Created vocabulary\n",
            "[2022-07-24 01:43:15,625] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[2022-07-24 01:43:28,411] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        2493.81   1447.68    0.00    0.00    0.00    0.00\n",
            " 15     200      142525.68  111785.78   65.85   64.57   67.19    0.66\n",
            " 30     400        2401.12  50895.46   67.85   63.16   73.30    0.68\n",
            " 46     600         356.11  48202.16   70.02   69.25   70.81    0.70\n",
            " 61     800         204.57  47958.72   67.69   65.81   69.68    0.68\n",
            " 76    1000         171.27  47486.35   66.88   64.30   69.68    0.67\n",
            " 92    1200         128.54  46745.99   68.86   68.93   68.78    0.69\n",
            "107    1400          59.28  46277.39   70.81   70.81   70.81    0.71\n",
            "123    1600          48.96  45261.02   70.25   69.47   71.04    0.70\n",
            "138    1800         130.84  44324.33   70.61   67.35   74.21    0.71\n",
            "153    2000         156.42  43198.36   67.31   64.33   70.59    0.67\n",
            "169    2200         154.61  41215.80   68.77   66.25   71.49    0.69\n",
            "184    2400          66.82  39271.38   68.88   67.46   70.36    0.69\n",
            "200    2600         405.57  36685.75   69.44   68.97   69.91    0.69\n",
            "215    2800         121.46  33190.66   67.82   65.07   70.81    0.68\n",
            "230    3000          84.51  29329.52   69.79   70.60   69.00    0.70\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "nlp/spacyNER_model/cross_valid/fold_1/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   71.35 \n",
            "NER R   72.99 \n",
            "NER F   72.16 \n",
            "SPEED   2743  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "MISC   76.47   43.33   55.32\n",
            "LOC    77.78   87.50   82.35\n",
            "DATE   52.00   76.47   61.90\n",
            "PERS   75.00   76.12   75.56\n",
            "ORG    68.75   78.57   73.33\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "nlp/spacyNER_model/cross_valid/fold_1/scores.json\u001b[0m\n",
            "<----- run k 2----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory: nlp/spacyNER_model/cross_valid/fold_2\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-24 02:12:28,106] [INFO] Set up nlp object from config\n",
            "[2022-07-24 02:12:28,113] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-07-24 02:12:28,116] [INFO] Created vocabulary\n",
            "[2022-07-24 02:12:28,116] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[2022-07-24 02:12:35,246] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        1321.51    667.98    0.25    0.15    0.77    0.00\n",
            " 13     200      150565.51  109992.92   58.76   53.46   65.22    0.59\n",
            " 26     400        2977.04  49655.76   65.36   59.58   72.38    0.65\n",
            " 40     600         476.09  46718.09   67.58   66.18   69.05    0.68\n",
            " 53     800         286.90  46100.75   66.83   62.84   71.36    0.67\n",
            " 66    1000         209.05  45976.72   64.84   60.71   69.57    0.65\n",
            " 80    1200         144.24  45186.44   66.75   63.93   69.82    0.67\n",
            " 93    1400        7794.92  44760.53   66.67   64.44   69.05    0.67\n",
            "106    1600         488.87  44214.65   66.83   64.52   69.31    0.67\n",
            "120    1800         157.45  42806.65   66.09   64.25   68.03    0.66\n",
            "133    2000         204.81  41622.47   63.91   60.88   67.26    0.64\n",
            "146    2200         190.00  40308.60   66.02   62.82   69.57    0.66\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "nlp/spacyNER_model/cross_valid/fold_2/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   75.57 \n",
            "NER R   76.44 \n",
            "NER F   76.00 \n",
            "SPEED   2523  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "MISC   55.17   53.33   54.24\n",
            "LOC    90.00   84.38   87.10\n",
            "DATE   81.25   76.47   78.79\n",
            "PERS   77.46   82.09   79.71\n",
            "ORG    73.33   78.57   75.86\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "nlp/spacyNER_model/cross_valid/fold_2/scores.json\u001b[0m\n",
            "<----- run k 3----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory: nlp/spacyNER_model/cross_valid/fold_3\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-24 02:33:18,084] [INFO] Set up nlp object from config\n",
            "[2022-07-24 02:33:18,090] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-07-24 02:33:18,094] [INFO] Created vocabulary\n",
            "[2022-07-24 02:33:18,095] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[2022-07-24 02:33:25,667] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        1676.14   1258.73    0.21    0.12    0.74    0.00\n",
            " 14     200      206590.05  115809.54   66.07   68.53   63.77    0.66\n",
            " 28     400        3758.66  52132.33   68.66   66.28   71.22    0.69\n",
            " 42     600         375.95  48808.35   68.20   66.75   69.73    0.68\n",
            " 57     800         262.18  47994.92   69.47   67.37   71.71    0.69\n",
            " 71    1000         161.29  47820.85   68.14   67.31   68.98    0.68\n",
            " 85    1200       22015.55  47793.25   66.91   66.10   67.74    0.67\n",
            "100    1400         367.38  46615.99   66.75   66.02   67.49    0.67\n",
            "114    1600          96.69  45676.91   68.83   66.82   70.97    0.69\n",
            "128    1800          81.04  44918.69   68.16   68.33   67.99    0.68\n",
            "142    2000         123.98  43700.87   67.39   65.65   69.23    0.67\n",
            "157    2200          75.67  41664.42   68.36   66.59   70.22    0.68\n",
            "171    2400         285.49  39948.22   68.32   68.15   68.49    0.68\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "nlp/spacyNER_model/cross_valid/fold_3/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   70.00 \n",
            "NER R   72.41 \n",
            "NER F   71.19 \n",
            "SPEED   2521  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "MISC   60.00   60.00   60.00\n",
            "LOC    78.79   81.25   80.00\n",
            "DATE   68.75   64.71   66.67\n",
            "PERS   69.44   74.63   71.94\n",
            "ORG    72.41   75.00   73.68\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "nlp/spacyNER_model/cross_valid/fold_3/scores.json\u001b[0m\n",
            "<----- run k 4----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory: nlp/spacyNER_model/cross_valid/fold_4\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-24 02:57:00,103] [INFO] Set up nlp object from config\n",
            "[2022-07-24 02:57:00,110] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-07-24 02:57:00,113] [INFO] Created vocabulary\n",
            "[2022-07-24 02:57:00,114] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[2022-07-24 02:57:07,551] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0         315.41    374.64    0.08    0.05    0.26    0.00\n",
            " 14     200      158337.59  107763.30   62.53   59.49   65.90    0.63\n",
            " 28     400        3035.70  48078.13   70.49   73.54   67.69    0.70\n",
            " 42     600         409.49  45583.02   71.48   71.95   71.03    0.71\n",
            " 57     800         224.35  44595.38   71.70   71.61   71.79    0.72\n",
            " 71    1000         174.88  44515.47   70.04   70.87   69.23    0.70\n",
            " 85    1200         298.73  44204.44   69.55   69.11   70.00    0.70\n",
            "100    1400         122.66  43190.23   70.04   67.46   72.82    0.70\n",
            "114    1600         101.04  42530.47   70.01   70.28   69.74    0.70\n",
            "128    1800         165.14  41850.34   69.58   71.86   67.44    0.70\n",
            "142    2000         188.21  40763.17   69.67   69.85   69.49    0.70\n",
            "157    2200         162.18  38749.36   70.30   69.60   71.03    0.70\n",
            "171    2400         100.35  37090.29   70.10   68.72   71.54    0.70\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "nlp/spacyNER_model/cross_valid/fold_4/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   71.68 \n",
            "NER R   71.26 \n",
            "NER F   71.47 \n",
            "SPEED   2756  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "MISC   70.83   56.67   62.96\n",
            "LOC    83.33   78.12   80.65\n",
            "DATE   54.17   76.47   63.41\n",
            "PERS   78.69   71.64   75.00\n",
            "ORG    61.76   75.00   67.74\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "nlp/spacyNER_model/cross_valid/fold_4/scores.json\u001b[0m\n",
            "<----- run k 5----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory: nlp/spacyNER_model/cross_valid/fold_5\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-24 03:19:25,664] [INFO] Set up nlp object from config\n",
            "[2022-07-24 03:19:25,671] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-07-24 03:19:25,674] [INFO] Created vocabulary\n",
            "[2022-07-24 03:19:25,675] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[2022-07-24 03:19:34,563] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0         315.41    374.64    0.74    0.45    2.06    0.01\n",
            " 13     200      171806.41  109469.21   58.75   61.56   56.19    0.59\n",
            " 26     400        3527.92  49567.94   66.89   65.49   68.35    0.67\n",
            " 40     600         605.19  46218.32   69.05   69.53   68.58    0.69\n",
            " 53     800         320.71  45703.00   69.22   68.07   70.41    0.69\n",
            " 66    1000         138.80  45457.13   69.14   72.25   66.28    0.69\n",
            " 80    1200         223.87  44723.59   67.97   68.29   67.66    0.68\n",
            " 93    1400        1990.14  44216.97   66.98   67.92   66.06    0.67\n",
            "106    1600         495.01  43640.29   67.15   70.35   64.22    0.67\n",
            "120    1800         129.08  42398.97   68.59   69.07   68.12    0.69\n",
            "133    2000         135.56  41222.22   67.73   67.35   68.12    0.68\n",
            "146    2200         114.07  39889.84   70.78   70.45   71.10    0.71\n",
            "160    2400          58.48  37680.07   68.21   69.01   67.43    0.68\n",
            "173    2600        1382.39  35554.26   69.86   71.19   68.58    0.70\n",
            "186    2800         148.22  32432.56   72.26   74.45   70.18    0.72\n",
            "200    3000          59.38  28500.77   72.08   74.09   70.18    0.72\n",
            "213    3200         168.53  24359.49   71.67   74.50   69.04    0.72\n",
            "226    3400          97.46  19841.55   72.16   75.31   69.27    0.72\n",
            "240    3600         107.66  15114.12   71.08   76.32   66.51    0.71\n",
            "253    3800        4063.69  11095.22   70.98   72.77   69.27    0.71\n",
            "266    4000         330.08   7435.42   71.84   74.88   69.04    0.72\n",
            "280    4200          75.26   4639.52   71.60   74.63   68.81    0.72\n",
            "293    4400          57.13   2833.83   72.24   73.18   71.33    0.72\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "nlp/spacyNER_model/cross_valid/fold_5/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   70.45 \n",
            "NER R   71.26 \n",
            "NER F   70.86 \n",
            "SPEED   2619  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "MISC   63.64   46.67   53.85\n",
            "LOC    73.53   78.12   75.76\n",
            "DATE   76.47   76.47   76.47\n",
            "PERS   75.71   79.10   77.37\n",
            "ORG    57.58   67.86   62.30\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "nlp/spacyNER_model/cross_valid/fold_5/scores.json\u001b[0m\n",
            "<----- run k 6----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory: nlp/spacyNER_model/cross_valid/fold_6\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-24 04:00:39,635] [INFO] Set up nlp object from config\n",
            "[2022-07-24 04:00:39,642] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2022-07-24 04:00:39,645] [INFO] Created vocabulary\n",
            "[2022-07-24 04:00:39,646] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[2022-07-24 04:00:47,062] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0         315.52    374.63    0.30    0.18    0.91    0.00\n",
            " 13     200      130369.79  108416.56   62.17   62.24   62.10    0.62\n",
            " 26     400        3455.13  49323.20   68.08   66.59   69.63    0.68\n",
            " 40     600         543.16  45854.84   69.92   68.03   71.92    0.70\n",
            " 53     800         354.48  45352.08   70.10   68.79   71.46    0.70\n",
            " 66    1000         203.71  45194.00   68.80   66.52   71.23    0.69\n",
            " 80    1200         142.70  44304.42   71.69   67.82   76.03    0.72\n",
            " 93    1400         217.83  43779.33   69.01   66.53   71.69    0.69\n",
            "106    1600         176.54  43237.34   69.74   67.09   72.60    0.70\n",
            "120    1800         120.67  41877.79   70.81   68.90   72.83    0.71\n",
            "133    2000         179.58  40780.28   71.52   69.23   73.97    0.72\n",
            "146    2200          87.33  39490.26   70.97   69.20   72.83    0.71\n",
            "160    2400         110.59  37283.10   68.98   67.69   70.32    0.69\n",
            "173    2600         631.33  35117.75   70.23   69.91   70.55    0.70\n",
            "186    2800          81.95  32220.27   73.68   73.85   73.52    0.74\n",
            "200    3000         167.46  28314.23   73.37   73.46   73.29    0.73\n",
            "213    3200          81.77  24111.17   71.90   71.66   72.15    0.72\n",
            "226    3400          80.94  19679.75   72.50   72.17   72.83    0.72\n",
            "240    3600          18.45  14927.62   70.86   70.94   70.78    0.71\n",
            "253    3800         109.50  10745.25   70.57   72.53   68.72    0.71\n",
            "266    4000         244.49   7318.24   71.73   69.21   74.43    0.72\n",
            "280    4200         409.04   4652.99   70.21   71.03   69.41    0.70\n",
            "293    4400          94.74   2795.59   72.73   71.52   73.97    0.73\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "nlp/spacyNER_model/cross_valid/fold_6/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   76.07 \n",
            "NER R   71.26 \n",
            "NER F   73.59 \n",
            "SPEED   2472  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "MISC   88.24   50.00   63.83\n",
            "LOC    80.65   78.12   79.37\n",
            "DATE   86.67   76.47   81.25\n",
            "PERS   73.53   74.63   74.07\n",
            "ORG    65.62   75.00   70.00\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "nlp/spacyNER_model/cross_valid/fold_6/scores.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section03\"></a>\n",
        "### Global Evaluation"
      ],
      "metadata": {
        "id": "iJDj8P9VQyv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Choose model\n",
        "\n",
        "Put the path of your select model"
      ],
      "metadata": {
        "id": "2-KDARLg8Dwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_model = './nlp/spacyNER_model/cross_valid/fold_6/model-best' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "CrLNyoHl5dCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Metrics"
      ],
      "metadata": {
        "id": "KfZL4b7h5TmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualisation Model"
      ],
      "metadata": {
        "id": "M7hMQKsGQ5Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#init GPU spacy\n",
        "import spacy\n",
        "gpu = spacy.prefer_gpu()\n",
        "print('GPU:', gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbCf9JE23OgC",
        "outputId": "9076d790-36e5-4e70-aa91-807a64f9be88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Choose text to analyze\n",
        "\n",
        "`text_clean` corresponds to a corrected and modernized transcription to the contemporary language. `text_brut` corresponds to the spellchecker/postprocess output of XML-ALTO. Finally, `text_htr` is an HTR transcription without filter or correction.\n",
        "The purpose of these different transcriptions is to visually observe the efficiency of the NER model"
      ],
      "metadata": {
        "id": "g7UQar8Q8JZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_clean = \"\"\"\n",
        "Comandancia de Armas\n",
        "Arauco Diciembre 14 de 1859\n",
        "En este momento recibí la nota de Usted fecha de ayer.\n",
        "Inmediatamente hice propio a Los Ángeles, participando al Señor Intendente, el éxito que ha tenido.\n",
        "Tendré mucho cuidado en sujetar todos los animales que arreen ilegalmente.\n",
        "Todavía no he recibido los 80 animales que le mandé, para hacer la correspondiente devolución a sus dueños.\n",
        "Aquí no hay novedad. El conductor don Salvador Hermosilla lleva 25 lanzas, con éstas son 124.\n",
        "Dios guarde a Usted,\n",
        "José del Carmen Díaz\n",
        "Al Señor Comandante en Jefe de la División Pacificadora de Arauco\n",
        "\n",
        "--------------------\n",
        "\n",
        "Gobierno Interino de\n",
        "Arauco Enero 2 de 1860\n",
        "Por el Gobernador del Departamento de Lautaro se me comunica lo que sigue:\n",
        "Santa Juana, Enero 2 de 1860\n",
        "Por la Intendencia de mi provincia en nota oficial fecha 29 del mes próximo pasado Nº 472, se me ordena poner a disposición de Usted al reo Juan [Hermosilla], titulado Sargento Mayor de la montonera de Patricio Silva; para que allí sea juzgado, y en su consecuencia se lo remito bajo segura custodia, y Usted se servirá acusar recibo. Dios guarde a Usted, Pascual Ruiz\n",
        "Yo lo transcribo a Usted para su conocimiento.\n",
        "Mientras Usted se sirva determinar de dicho reo, he dispuesto mandarlo a bordo del Vapor “Maipú”, para la mayor seguridad.\n",
        "Dios guarde a Usted,\n",
        "José del Carmen Díaz\n",
        "\"\"\"\n",
        "\n",
        "text_brut = \"\"\"\"\"\"\n",
        "\n",
        "text_htr = \"\"\"\n",
        "Comand^oo de armas\n",
        "En este promente recibi la nota de Ue pha. de Aytt.\n",
        "Inmediatamente hire prepio a los Anpeles, participando al Sõr Intend^te, el endito que ha tenido.\n",
        "Tendré mucho cuidado en sufetar todos los animales que Vanien ilegalmente.\n",
        "Jodabia no he recibo do los 80 animales que le mande, para hacer la corespondiente débolucion asus dueños\n",
        "Aqui no hai novedad.\n",
        "El conductor D^n Salvador Elmnosilla lleba 25 lanzar, con estas son 124.\n",
        "Naueo Obre. 14 de 1859.\n",
        "Dios gue. aUd.\n",
        "Jdel C. Dize\n",
        "Al Señor Coronel Comand^\n",
        "U Jefe dela Divicion pacificadora de Arauco.\n",
        "\n",
        "--------------------\n",
        "\n",
        "E^te inteime de\n",
        "or el Gobemador del dep^t de Sauteno se me comunica lo que sigue.\n",
        "Santa Juana Conero 2 de 1860.\n",
        "Por la Intend^a demi provincia en nota oficial tha 29 del mes ep^a No N72, seme ordena poner a disporicion de Ud al reo Juan llmorcilla, tetulado Sarjento mayor dela montonera de Patricio Silva; para que allí sea juegado; i en su concecuencio selo remito bajo segura custodia; i Ud.\n",
        "se servirá acuzarme recibo. Dios que a Us Parcual Ruir.\n",
        "Tolo lo trarcribo a Ul para su conocimiento.\n",
        "Mientras Ud se sirva determinas de dicho reo, he dispueto mandarlo abordo del vapor Maipú, para la mayor seguridad.\n",
        "Arauco Lonezo 2 de 1860\n",
        "No 3\n",
        "35\n",
        "1\n",
        "Al Sõr Comand^o en fefe dela Piarcion deoperaciones de Arauco.\n",
        "Dios gu~e a Ud\n",
        "Jel C. Diaz\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bY5f5RL6mX_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text_clean #@param [\"text_clean\", \"text_brut\", \"text_htr\"] {type:\"raw\"}"
      ],
      "metadata": {
        "id": "0kAQHDDk7omp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Process\n",
        "If you want to use a non-transformers model, you need to install spacy classical version"
      ],
      "metadata": {
        "id": "uZTNeKWZ8OiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing tokenization\n",
        "nlp = spacy.load(path_model)\n",
        "doc_clean = nlp(text)"
      ],
      "metadata": {
        "id": "_D6laUUP3SUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "from pathlib import Path\n",
        "\n",
        "#option visualizers ent\n",
        "colors = {\n",
        "    \"MISC\": \"#808D8E\",\n",
        "    \"LOC\": \"#766C7F\",\n",
        "    \"PERS\": \"#947EB0\",\n",
        "    \"DATE\": \"#A3A5C3\",\n",
        "    \"ORG\": \"#A9D2D5\"\n",
        "    }\n",
        "options= {\"ents\": [\"MISC\", \"LOC\", \"PERS\", \"DATE\", \"ORG\"], \"colors\": colors}\n",
        "\n",
        "#render\n",
        "html = displacy.render(doc_clean, style=\"ent\", jupyter=True, options=options, page=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "id": "SqEwX_yg3W6g",
        "outputId": "3e374bab-4c81-445e-c486-e1854f875e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>\n",
              "<mark class=\"entity\" style=\"background: #A9D2D5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Comandancia de Armas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "</br>\n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Arauco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #A3A5C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Diciembre 14 de 1859\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</br>En este momento recibí la nota de Usted fecha de \n",
              "<mark class=\"entity\" style=\"background: #A3A5C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    ayer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".</br>Inmediatamente hice propio a \n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Los Ángeles\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", participando al Señor \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Intendente\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              ", el éxito que ha tenido.</br>Tendré mucho cuidado en sujetar todos los \n",
              "<mark class=\"entity\" style=\"background: #808D8E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    animales\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " que arreen ilegalmente.</br>Todavía no he recibido los \n",
              "<mark class=\"entity\" style=\"background: #808D8E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    80 animales\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " que le mandé, para hacer la correspondiente devolución a sus \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    dueños\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              ".</br>Aquí no hay novedad. El conductor don \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Salvador Hermosilla\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              " lleva \n",
              "<mark class=\"entity\" style=\"background: #808D8E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    25 lanzas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ", con éstas son 124.</br>Dios guarde a Usted,</br>\n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    José del Carmen Díaz\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "</br>Al Señor \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Comandante en Jefe\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              " de la \n",
              "<mark class=\"entity\" style=\"background: #A9D2D5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    División Pacificadora\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " de \n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Arauco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              "</br></br>--------------------</br></br>\n",
              "<mark class=\"entity\" style=\"background: #A9D2D5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Gobierno Interino\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " de</br>\n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Arauco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " Enero \n",
              "<mark class=\"entity\" style=\"background: #A3A5C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2 de 1860\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</br>Por el \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Gobernador\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              " del \n",
              "<mark class=\"entity\" style=\"background: #A9D2D5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Departamento\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " de \n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lautaro\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " se me comunica lo que sigue:</br>\n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Santa Juana\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #A3A5C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Enero 2 de 1860\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</br>Por la \n",
              "<mark class=\"entity\" style=\"background: #A9D2D5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Intendencia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " de mi \n",
              "<mark class=\"entity\" style=\"background: #A9D2D5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    provincia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " en nota oficial \n",
              "<mark class=\"entity\" style=\"background: #A3A5C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    fecha 29 del mes próximo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " pasado Nº 472, se me ordena poner a disposición de Usted al reo \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Juan [Hermosilla\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "], titulado \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sargento Mayor\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              " de la \n",
              "<mark class=\"entity\" style=\"background: #A9D2D5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    montonera\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " de \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Patricio Silva\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "; para que allí sea juzgado, y en su consecuencia se lo remito bajo segura custodia, y Usted se servirá acusar recibo. Dios guarde a Usted, \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Pascual Ruiz\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "</br>Yo lo transcribo a Usted para su conocimiento.</br>Mientras Usted se sirva determinar de dicho reo, he dispuesto mandarlo a bordo del \n",
              "<mark class=\"entity\" style=\"background: #808D8E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Vapor “Maipú”\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              ", para la mayor seguridad.</br>Dios guarde a Usted,</br>\n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    José del Carmen Díaz\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "</br></div>\n",
              "</figure>\n",
              "</body>\n",
              "</html></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
