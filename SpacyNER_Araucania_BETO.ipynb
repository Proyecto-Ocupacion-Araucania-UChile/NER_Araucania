{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " SpacyNER_Araucania_BETO.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "L0RtQ3GpQktv"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Introduction\n",
        "\n",
        "\n",
        "In this tutorial, we will refine a transformation model for *Named Entity Recognition* based on the BETO model (a Spanish adaptation of the BERT model). \n",
        "This tutorial aims at producing a tranformers model via the spacy and sklearn library by proceeding to the cross validation technique.\n",
        "\n",
        "**Warning** : This processing chain works only via the notebook interface (when using the GPU colab). It is possible to use the native *subsystem* library to execute bash commands."
      ],
      "metadata": {
        "id": "Qyjc2RsZ4wXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Flow of the notebook\n",
        "\n",
        "The notebook will be divided into seperate sections to provide a organized walk through for the process used.\n",
        "\n",
        "1. [Checking system and requirements](#section00)\n",
        "2. [Configuration system](#section01)\n",
        "3. [Finetuning](#section02) \\\n",
        "3-1. [Preprocessing](#section021) \\\n",
        "3-2. [Training](#section022)\n",
        "4. [Global evaluation](#section03)"
      ],
      "metadata": {
        "id": "wtDoCtIqA23h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section00\"></a>\n",
        "####Checking"
      ],
      "metadata": {
        "id": "LainhQPbPiWb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3JC4YNX-Gil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad270fa4-3d65-4f78-858d-d40cfcb107b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul 25 16:57:17 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#Check gpu activity\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#open google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6TVaKmzj-JZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc2f6aa-ea5f-48d8-c007-fddd73a20e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### install dependencies"
      ],
      "metadata": {
        "id": "7dVR7p4dQcom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pandas\n",
        "!pip install -U scikit-learn\n",
        "!pip install -U spacy[transformers]"
      ],
      "metadata": {
        "id": "lCApoHl0-Lu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57ee9660-1331-472d-a2c3-481a01b5f7c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy[transformers] in /usr/local/lib/python3.7/dist-packages (3.4.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (8.1.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.0.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (4.64.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.9.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.6.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.0.9)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.0.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.4.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.0.7)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.9.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (1.21.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (4.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.23.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (0.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy[transformers]) (21.3)\n",
            "Collecting spacy-transformers<1.2.0,>=1.1.2\n",
            "  Downloading spacy_transformers-1.1.7-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy[transformers]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy[transformers]) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy[transformers]) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[transformers]) (1.24.3)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 9.3 MB/s \n",
            "\u001b[?25hCollecting transformers<4.21.0,>=3.4.0\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (1.12.0+cu113)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy[transformers]) (0.7.8)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (4.12.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 10.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.0 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.21.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[transformers]) (2022.6.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy[transformers]) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy[transformers]) (2.0.1)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, spacy-alignments, spacy-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 spacy-alignments-0.8.5 spacy-transformers-1.1.7 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section01\"></a>\n",
        "####Configuration"
      ],
      "metadata": {
        "id": "L0RtQ3GpQktv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for dev and train data\n",
        "import os\n",
        "#specific train\n",
        "if not os.path.isdir('/content/drive/MyDrive/nlp'):\n",
        "  os.mkdir('/content/drive/MyDrive/nlp')\n",
        "#data\n",
        "if not os.path.isdir('/content/drive/MyDrive/nlp/spacyNER_data'):\n",
        "  os.mkdir('/content/drive/MyDrive/nlp/spacyNER_data')\n",
        "#model \n",
        "if not os.path.isdir('/content/drive/MyDrive/nlp/spacyNER_model'):\n",
        "  os.mkdir('/content/drive/MyDrive/nlp/spacyNER_model')\n",
        "#cross_validation\n",
        "if not os.path.isdir('/content/drive/MyDrive/nlp/spacyNER_model/cross_valid'):\n",
        "  os.mkdir('/content/drive/MyDrive/nlp/spacyNER_model/cross_valid')"
      ],
      "metadata": {
        "id": "jbXoo5Xs-NZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy.require_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CaDeeL6-O5t",
        "outputId": "b95f8f27-50a2-41ca-9382-e88d8b2910a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section02'></a>\n",
        "### Finetuning"
      ],
      "metadata": {
        "id": "l6WEZjlB47nE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id='section021'></a>\n",
        "####Preprocessing"
      ],
      "metadata": {
        "id": "n02SBdZPQp17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataframe, train_ratio: float):\n",
        "  \"\"\"\n",
        "  function to split dataframe with ration as you want\n",
        "  :dataframe: dataframe\n",
        "  :train_ratio: float, ratio of split training\n",
        "  :return: None\n",
        "  \"\"\"\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  assert(train_ratio < 1), \"the number must be value between 0 and 1\"\n",
        "\n",
        "  train_df, test_df = train_test_split(dataframe, test_size= 1 - train_ratio)\n",
        "  \n",
        "  return train_df, test_df"
      ],
      "metadata": {
        "id": "3D5VUh6r-QjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_binary(name: str, data):\n",
        "  \"\"\"\n",
        "  function to convert dataset (Dataframe) in binary spacy format\n",
        "  :name: str, name of binary file outpout\n",
        "  :data: dataframe\n",
        "  :return: count of tokens and entities in file\n",
        "  \"\"\"\n",
        "  from spacy.tokens import DocBin\n",
        "  \n",
        "  #Generate tokenization\n",
        "  nlp = spacy.blank(\"es\")\n",
        "  # the DocBin will store the example documents\n",
        "  db = DocBin(attrs=[\"ENT_IOB\", \"ENT_TYPE\"])\n",
        "\n",
        "  #counting variable\n",
        "  n_token = 0\n",
        "  n_entities = 0\n",
        "\n",
        "  for index, row in data.iterrows():\n",
        "    doc = nlp(row[\"text\"])\n",
        "    n_token += len(doc)\n",
        "    n_entities += len(row[\"label\"])\n",
        "    ents = []\n",
        "    for ent in row[\"label\"]:\n",
        "      start, end, label = tuple(ent)\n",
        "      span = doc.char_span(start, end, label=label)\n",
        "      if span is not None:\n",
        "        ents.append(span)\n",
        "      else:\n",
        "        n_entities -= 1\n",
        "    try:\n",
        "      doc.ents = ents\n",
        "    except TypeError:\n",
        "      print(ents)\n",
        "      pass\n",
        "    db.add(doc)\n",
        "    db.to_disk(f\"/content/drive/MyDrive/nlp/spacyNER_data/{name}.spacy\")\n",
        "  return n_token, n_entities"
      ],
      "metadata": {
        "id": "rAbRo5h1-R7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_json(data: dict):\n",
        "  \"\"\"\n",
        "  Export json file with metadata's models\n",
        "  \n",
        "  :data: dictionary of metadata\n",
        "  \"\"\"\n",
        "  import json\n",
        "\n",
        "  with open(\"/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/metadata.json\", \"w\", encoding=\"utf-8\") as json_files:\n",
        "    json.dump(data, json_files, ensure_ascii=False, indent=3)"
      ],
      "metadata": {
        "id": "au96vnz-R0ak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section022\"></a>\n",
        "#### Training"
      ],
      "metadata": {
        "id": "gZhBMJ6sQurA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration file\n",
        "config = '/content/drive/MyDrive/nlp/base_config_NoTransformers.cfg' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "UK9n7GrK3ZkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "\n",
        "#import dataset\n",
        "df = pd.read_json(\"/content/drive/MyDrive/nlp/spacyNER_data/dataset_araucania.jsonl\", lines = True, encoding=\"utf-8\")\n",
        "\n",
        "#structure dataset\n",
        "\n",
        "dataset = split_dataset(df, 0.90)\n",
        "\n",
        "X = dataset[0]\n",
        "test_dataset = convert_binary(\"test\", dataset[1])\n",
        "print(\"test: \" + str(test_dataset[0]) + \" tokens, \" + str(test_dataset[1]) + \" entities\")\n",
        "\n",
        "#K-Fold configuration\n",
        "kf = KFold(n_splits=6, shuffle = True, random_state = 2)\n",
        "\n",
        "#variables\n",
        "n = 0\n",
        "results = {}\n",
        "\n",
        "#loop on k\n",
        "for train_index , test_index in kf.split(X):\n",
        "  \n",
        "  #enumeration\n",
        "  n += 1\n",
        "  print(\"<----- run k \" + str(n) + \"----->\")\n",
        "\n",
        "  #path\n",
        "  os.mkdir(f\"/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_{str(n)}\")\n",
        "  path_ouput = f\"/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_{str(n)}\"\n",
        "  best_model = f\"/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_{str(n)}/model-best\"\n",
        "  json_output = f\"/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_{str(n)}/scores.json\"\n",
        "\n",
        "  #convert in binary format\n",
        "  X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
        "  train_binary = convert_binary(\"train\",X_train)\n",
        "  dev_binary = convert_binary(\"dev\",X_test)\n",
        "\n",
        "  #metadata\n",
        "  results[n] ={\n",
        "                    \"test_data\": [test_dataset[0],test_dataset[1]],\n",
        "                    \"train_data\" : [train_binary[0],train_binary[1]],\n",
        "                    \"dev_data\" : [dev_binary[0],dev_binary[1]]\n",
        "                }\n",
        "\n",
        "  #init config\n",
        "  !python -m spacy init fill-config $config config.cfg\n",
        "\n",
        "  #training\n",
        "  !python -m spacy train config.cfg --paths.train /content/drive/MyDrive/nlp/spacyNER_data/train.spacy --paths.dev /content/drive/MyDrive/nlp/spacyNER_data/dev.spacy -g 0 --output $path_ouput\n",
        "  \n",
        "  #evaluation\n",
        "  !python -m spacy evaluate $best_model /content/drive/MyDrive/nlp/spacyNER_data/test.spacy --output $json_output --gold-preproc --gpu-id 0\n",
        "\n",
        "#export json metadata\n",
        "export_json(results)"
      ],
      "metadata": {
        "id": "FknhDHzR2T2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db738a27-fb71-44ba-cc1b-64705c759fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: 3104 tokens, 276 entities\n",
            "<----- run k 1----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_1\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-25 15:30:09,741] [INFO] Set up nlp object from config\n",
            "[2022-07-25 15:30:09,751] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2022-07-25 15:30:09,755] [INFO] Created vocabulary\n",
            "[2022-07-25 15:30:09,756] [INFO] Finished initializing nlp object\n",
            "[2022-07-25 15:30:11,929] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     81.09    1.08    0.68    2.56    0.01\n",
            "  1     200        858.01   6328.20   43.28   51.97   37.08    0.43\n",
            "  3     400        321.34   2741.90   56.36   57.26   55.50    0.56\n",
            "  5     600        419.45   1844.17   58.07   65.08   52.43    0.58\n",
            "  6     800        566.83   1310.13   59.69   61.13   58.31    0.60\n",
            "  8    1000       1448.14   1148.77   59.79   61.07   58.57    0.60\n",
            " 10    1200        456.51    857.44   62.69   63.52   61.89    0.63\n",
            " 11    1400        574.04    727.55   61.13   64.23   58.31    0.61\n",
            " 13    1600        550.32    602.69   59.72   60.10   59.34    0.60\n",
            " 15    1800        487.78    469.90   65.47   71.17   60.61    0.65\n",
            " 17    2000        621.65    432.89   62.87   66.86   59.34    0.63\n",
            " 19    2200        823.65    484.63   63.42   65.31   61.64    0.63\n",
            " 22    2400        699.28    490.98   60.72   61.36   60.10    0.61\n",
            " 26    2600        724.61    412.81   62.45   64.40   60.61    0.62\n",
            " 30    2800        579.35    309.06   63.29   68.14   59.08    0.63\n",
            " 36    3000        863.35    344.89   61.23   64.15   58.57    0.61\n",
            " 43    3200        650.48    244.80   60.77   62.84   58.82    0.61\n",
            " 51    3400        682.95    223.60   63.50   65.49   61.64    0.64\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_1/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   66.22 \n",
            "NER R   53.99 \n",
            "NER F   59.48 \n",
            "SPEED   5186  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "PERS   69.66   59.62   64.25\n",
            "DATE   48.15   50.00   49.06\n",
            "ORG    48.89   62.86   55.00\n",
            "LOC    91.11   69.49   78.85\n",
            "MISC   57.89   21.15   30.99\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_1/scores.json\u001b[0m\n",
            "<----- run k 2----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_2\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-25 15:37:49,938] [INFO] Set up nlp object from config\n",
            "[2022-07-25 15:37:49,948] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2022-07-25 15:37:49,952] [INFO] Created vocabulary\n",
            "[2022-07-25 15:37:49,953] [INFO] Finished initializing nlp object\n",
            "[2022-07-25 15:37:52,105] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    144.23    1.69    1.16    3.13    0.02\n",
            "  1     200       2186.10   6661.02   50.10   68.48   39.50    0.50\n",
            "  3     400        681.52   3293.55   60.13   60.70   59.56    0.60\n",
            "  5     600        451.56   2081.40   66.44   72.32   61.44    0.66\n",
            "  6     800        574.44   1455.32   62.38   64.03   60.82    0.62\n",
            "  8    1000        558.97   1174.63   61.87   64.73   59.25    0.62\n",
            " 10    1200        558.02    939.05   63.90   71.15   57.99    0.64\n",
            " 11    1400        527.37    687.45   64.25   71.54   58.31    0.64\n",
            " 13    1600        499.50    577.53   64.09   65.89   62.38    0.64\n",
            " 15    1800        689.30    558.50   62.75   65.53   60.19    0.63\n",
            " 17    2000        582.12    485.02   65.16   73.33   58.62    0.65\n",
            " 18    2200       1955.13    430.58   65.00   69.40   61.13    0.65\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_2/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   66.82 \n",
            "NER R   53.99 \n",
            "NER F   59.72 \n",
            "SPEED   5229  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "PERS   66.67   51.92   58.38\n",
            "DATE   68.18   57.69   62.50\n",
            "ORG    61.76   60.00   60.87\n",
            "LOC    82.76   81.36   82.05\n",
            "MISC   39.29   21.15   27.50\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_2/scores.json\u001b[0m\n",
            "<----- run k 3----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_3\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-25 15:42:41,553] [INFO] Set up nlp object from config\n",
            "[2022-07-25 15:42:41,563] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2022-07-25 15:42:41,567] [INFO] Created vocabulary\n",
            "[2022-07-25 15:42:41,568] [INFO] Finished initializing nlp object\n",
            "[2022-07-25 15:42:43,690] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    121.00    1.50    1.38    1.65    0.02\n",
            "  1     200        567.86   6303.45   45.23   57.94   37.09    0.45\n",
            "  3     400        408.82   2892.13   55.81   61.87   50.82    0.56\n",
            "  5     600       3304.26   2107.14   58.58   63.46   54.40    0.59\n",
            "  6     800        493.99   1405.83   59.81   59.73   59.89    0.60\n",
            "  8    1000        374.26    891.54   64.30   69.77   59.62    0.64\n",
            " 10    1200        493.08    816.73   59.54   62.80   56.59    0.60\n",
            " 11    1400        553.32    741.04   64.94   72.95   58.52    0.65\n",
            " 13    1600        449.40    532.49   62.42   71.79   55.22    0.62\n",
            " 15    1800        575.47    480.80   63.04   65.87   60.44    0.63\n",
            " 17    2000        523.28    434.61   62.21   66.05   58.79    0.62\n",
            " 19    2200        546.86    384.98   61.95   68.44   56.59    0.62\n",
            " 21    2400        910.66    475.70   64.33   72.26   57.97    0.64\n",
            " 24    2600        765.48    448.92   58.05   64.12   53.02    0.58\n",
            " 28    2800        582.08    326.58   61.56   64.94   58.52    0.62\n",
            " 33    3000        803.39    355.29   61.54   68.23   56.04    0.62\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_3/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   67.11 \n",
            "NER R   55.43 \n",
            "NER F   60.71 \n",
            "SPEED   5280  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "PERS   65.59   58.65   61.93\n",
            "DATE   59.09   50.00   54.17\n",
            "ORG    59.46   62.86   61.11\n",
            "LOC    89.36   71.19   79.25\n",
            "MISC   51.72   28.85   37.04\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_3/scores.json\u001b[0m\n",
            "<----- run k 4----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_4\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-25 15:49:17,011] [INFO] Set up nlp object from config\n",
            "[2022-07-25 15:49:17,020] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2022-07-25 15:49:17,025] [INFO] Created vocabulary\n",
            "[2022-07-25 15:49:17,026] [INFO] Finished initializing nlp object\n",
            "[2022-07-25 15:49:19,124] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    111.23    0.00    0.00    0.00    0.00\n",
            "  1     200       2084.69   6552.77   43.34   51.11   37.62    0.43\n",
            "  3     400        315.42   2824.73   54.92   54.48   55.37    0.55\n",
            "  5     600        460.51   2005.91   63.61   67.63   60.05    0.64\n",
            "  6     800       1457.05   1414.06   62.36   65.14   59.81    0.62\n",
            "  8    1000       2089.52   1135.38   67.50   72.90   62.85    0.68\n",
            " 10    1200        476.35    805.98   63.13   66.84   59.81    0.63\n",
            " 12    1400        528.89    676.40   62.58   70.80   56.07    0.63\n",
            " 13    1600        531.02    563.52   64.76   69.33   60.75    0.65\n",
            " 15    1800        591.01    538.53   61.27   66.85   56.54    0.61\n",
            " 17    2000        471.86    421.30   61.63   62.29   60.98    0.62\n",
            " 19    2200        617.34    410.79   64.57   69.84   60.05    0.65\n",
            " 22    2400        641.64    380.97   65.55   66.91   64.25    0.66\n",
            " 25    2600        823.58    420.48   65.41   70.84   60.75    0.65\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_4/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   67.43 \n",
            "NER R   53.26 \n",
            "NER F   59.51 \n",
            "SPEED   5068  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "PERS   71.23   50.00   58.76\n",
            "DATE   77.27   65.38   70.83\n",
            "ORG    53.85   60.00   56.76\n",
            "LOC    76.36   71.19   73.68\n",
            "MISC   51.72   28.85   37.04\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_4/scores.json\u001b[0m\n",
            "<----- run k 5----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_5\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-25 15:54:50,056] [INFO] Set up nlp object from config\n",
            "[2022-07-25 15:54:50,066] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2022-07-25 15:54:50,070] [INFO] Created vocabulary\n",
            "[2022-07-25 15:54:50,071] [INFO] Finished initializing nlp object\n",
            "[2022-07-25 15:54:52,172] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    121.00    1.11    1.16    1.07    0.01\n",
            "  1     200       5078.63   5814.50   43.54   49.46   38.89    0.44\n",
            "  3     400        358.90   2766.76   55.91   65.99   48.50    0.56\n",
            "  5     600        405.38   1719.20   61.50   70.95   54.27    0.62\n",
            "  6     800        473.40   1301.93   56.79   60.34   53.63    0.57\n",
            "  8    1000        504.13   1018.57   58.10   60.89   55.56    0.58\n",
            " 10    1200        481.12    855.26   61.73   67.25   57.05    0.62\n",
            " 11    1400        485.56    674.67   60.31   61.94   58.76    0.60\n",
            " 13    1600        498.43    600.16   58.18   58.24   58.12    0.58\n",
            " 15    1800        547.44    552.65   60.29   62.88   57.91    0.60\n",
            " 17    2000        585.64    476.98   61.26   64.76   58.12    0.61\n",
            " 19    2200        752.63    490.70   61.21   65.45   57.48    0.61\n",
            " 22    2400        821.34    510.25   61.33   64.92   58.12    0.61\n",
            " 26    2600        671.02    434.30   62.27   67.93   57.48    0.62\n",
            " 31    2800        692.43    337.96   61.69   63.43   60.04    0.62\n",
            " 38    3000        815.16    407.14   61.44   63.62   59.40    0.61\n",
            " 45    3200        925.32    381.49   61.50   65.85   57.69    0.62\n",
            " 53    3400        604.75    262.22   64.43   70.38   59.40    0.64\n",
            " 61    3600        759.24    257.51   61.04   63.51   58.76    0.61\n",
            " 68    3800        672.90    217.72   61.48   68.50   55.77    0.61\n",
            " 76    4000       1344.23    221.90   61.27   63.74   58.97    0.61\n",
            " 84    4200        611.03    188.95   62.36   63.90   60.90    0.62\n",
            " 91    4400        867.48    180.12   61.49   66.09   57.48    0.61\n",
            " 99    4600        946.33    171.09   60.52   63.90   57.48    0.61\n",
            "107    4800        898.01    160.55   61.27   66.75   56.62    0.61\n",
            "115    5000       1225.53    179.34   60.39   64.41   56.84    0.60\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_5/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   66.96 \n",
            "NER R   55.07 \n",
            "NER F   60.44 \n",
            "SPEED   5152  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "PERS   60.92   50.96   55.50\n",
            "DATE   77.27   65.38   70.83\n",
            "ORG    64.71   62.86   63.77\n",
            "MISC   41.94   25.00   31.33\n",
            "LOC    88.68   79.66   83.93\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_5/scores.json\u001b[0m\n",
            "<----- run k 6----->\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_6\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-07-25 16:06:18,445] [INFO] Set up nlp object from config\n",
            "[2022-07-25 16:06:18,455] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2022-07-25 16:06:18,459] [INFO] Created vocabulary\n",
            "[2022-07-25 16:06:18,460] [INFO] Finished initializing nlp object\n",
            "[2022-07-25 16:06:20,511] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00    102.77    0.00    0.00    0.00    0.00\n",
            "  1     200       1584.05   5869.28   43.48   51.95   37.38    0.43\n",
            "  3     400        357.48   2740.95   51.36   52.04   50.70    0.51\n",
            "  5     600        400.90   1776.93   56.01   61.86   51.17    0.56\n",
            "  6     800        510.35   1366.54   54.65   55.85   53.50    0.55\n",
            "  8    1000        460.57    987.01   56.62   58.99   54.44    0.57\n",
            " 10    1200        589.04    839.65   56.15   59.95   52.80    0.56\n",
            " 11    1400        448.58    629.99   58.93   66.67   52.80    0.59\n",
            " 13    1600        513.33    570.27   54.42   55.61   53.27    0.54\n",
            " 15    1800        671.63    591.33   53.73   55.47   52.10    0.54\n",
            " 17    2000        672.58    505.29   55.24   58.49   52.34    0.55\n",
            " 19    2200        661.76    453.24   54.57   56.19   53.04    0.55\n",
            " 22    2400        726.29    445.48   58.23   59.51   57.01    0.58\n",
            " 26    2600        790.11    440.71   55.52   57.68   53.50    0.56\n",
            " 31    2800        840.54    452.10   57.93   62.84   53.74    0.58\n",
            " 37    3000        766.84    397.04   56.86   60.37   53.74    0.57\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_6/model-last\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "================================== Results ==================================\u001b[0m\n",
            "\n",
            "TOK     100.00\n",
            "NER P   69.96 \n",
            "NER R   56.52 \n",
            "NER F   62.53 \n",
            "SPEED   5099  \n",
            "\n",
            "\u001b[1m\n",
            "=============================== NER (per type) ===============================\u001b[0m\n",
            "\n",
            "           P       R       F\n",
            "PERS   73.56   61.54   67.02\n",
            "DATE   70.59   46.15   55.81\n",
            "ORG    69.23   51.43   59.02\n",
            "LOC    69.84   74.58   72.13\n",
            "MISC   60.00   34.62   43.90\n",
            "\n",
            "\u001b[38;5;2m✔ Saved results to\n",
            "/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_6/scores.json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name=\"section03\"></a>\n",
        "### Global Evaluation"
      ],
      "metadata": {
        "id": "iJDj8P9VQyv7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Choose model\n",
        "\n",
        "Put the path of your select model"
      ],
      "metadata": {
        "id": "2-KDARLg8Dwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_model = '/content/drive/MyDrive/nlp/spacyNER_model/cross_valid/fold_6/model-best' #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "CrLNyoHl5dCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Metrics"
      ],
      "metadata": {
        "id": "KfZL4b7h5TmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualisation Model"
      ],
      "metadata": {
        "id": "M7hMQKsGQ5Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#init GPU spacy\n",
        "import spacy\n",
        "#gpu = spacy.prefer_gpu()\n",
        "#print('GPU:', gpu)"
      ],
      "metadata": {
        "id": "cbCf9JE23OgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Choose text to analyze\n",
        "\n",
        "`text_clean` corresponds to a corrected and modernized transcription to the contemporary language. `text_brut` corresponds to the spellchecker/postprocess output of XML-ALTO. Finally, `text_htr` is an HTR transcription without filter or correction.\n",
        "The purpose of these different transcriptions is to visually observe the efficiency of the NER model"
      ],
      "metadata": {
        "id": "g7UQar8Q8JZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_clean = \"\"\"\n",
        "Comandancia de Armas\n",
        "Arauco Diciembre 14 de 1859\n",
        "En este momento recibí la nota de Usted fecha de ayer.\n",
        "Inmediatamente hice propio a Los Ángeles, participando al Señor Intendente, el éxito que ha tenido.\n",
        "Tendré mucho cuidado en sujetar todos los animales que arreen ilegalmente.\n",
        "Todavía no he recibido los 80 animales que le mandé, para hacer la correspondiente devolución a sus dueños.\n",
        "Aquí no hay novedad. El conductor don Salvador [Hermosilla] lleva 25 lanzas, con éstas son 124.\n",
        "Dios guarde a Usted,\n",
        "José del Carmen Díaz\n",
        "Al Señor Comandante en Jefe de la División Pacificadora de Arauco\n",
        "\n",
        "--------------------\n",
        "\n",
        "Gobierno Interino de\n",
        "Arauco Enero 2 de 1860\n",
        "Por el Gobernador del Departamento de Lautaro se me comunica lo que sigue:\n",
        "Santa Juana, Enero 2 de 1860\n",
        "Por la Intendencia de mi provincia en nota oficial fecha 29 del mes próximo pasado Nº 472, se me ordena poner a disposición de Usted al reo Juan Hermosilla, titulado Sargento Mayor de la montonera de Patricio Silva; para que allí sea juzgado, y en su consecuencia se lo remito bajo segura custodia, y Usted se servirá acusar recibo. Dios guarde a Usted, Pascual Ruiz\n",
        "Yo lo transcribo a Usted para su conocimiento.\n",
        "Mientras Usted se sirva determinar de dicho reo, he dispuesto mandarlo a bordo del Vapor “Maipú”, para la mayor seguridad.\n",
        "Dios guarde a Usted,\n",
        "José del Carmen Díaz\n",
        "\"\"\"\n",
        "\n",
        "text_brut = \"\"\"\"\"\"\n",
        "\n",
        "text_htr = \"\"\"\n",
        "Comand^oo de armas\n",
        "En este promente recibi la nota de Ue pha. de Aytt.\n",
        "Inmediatamente hire prepio a los Anpeles, participando al Sõr Intend^te, el endito que ha tenido.\n",
        "Tendré mucho cuidado en sufetar todos los animales que Vanien ilegalmente.\n",
        "Jodabia no he recibo do los 80 animales que le mande, para hacer la corespondiente débolucion asus dueños\n",
        "Aqui no hai novedad.\n",
        "El conductor D^n Salvador Elmnosilla lleba 25 lanzar, con estas son 124.\n",
        "Naueo Obre. 14 de 1859.\n",
        "Dios gue. aUd.\n",
        "Jdel C. Dize\n",
        "Al Señor Coronel Comand^\n",
        "U Jefe dela Divicion pacificadora de Arauco.\n",
        "\n",
        "--------------------\n",
        "\n",
        "E^te inteime de\n",
        "or el Gobemador del dep^t de Sauteno se me comunica lo que sigue.\n",
        "Santa Juana Conero 2 de 1860.\n",
        "Por la Intend^a demi provincia en nota oficial tha 29 del mes ep^a No N72, seme ordena poner a disporicion de Ud al reo Juan llmorcilla, tetulado Sarjento mayor dela montonera de Patricio Silva; para que allí sea juegado; i en su concecuencio selo remito bajo segura custodia; i Ud.\n",
        "se servirá acuzarme recibo. Dios que a Us Parcual Ruir.\n",
        "Tolo lo trarcribo a Ul para su conocimiento.\n",
        "Mientras Ud se sirva determinas de dicho reo, he dispueto mandarlo abordo del vapor Maipú, para la mayor seguridad.\n",
        "Arauco Lonezo 2 de 1860\n",
        "No 3\n",
        "35\n",
        "1\n",
        "Al Sõr Comand^o en fefe dela Piarcion deoperaciones de Arauco.\n",
        "Dios gu~e a Ud\n",
        "Jel C. Diaz\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "bY5f5RL6mX_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text_htr #@param [\"text_clean\", \"text_brut\", \"text_htr\"] {type:\"raw\"}"
      ],
      "metadata": {
        "id": "0kAQHDDk7omp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Process\n",
        "If you want to use a non-transformers model, you need to install spacy classical version"
      ],
      "metadata": {
        "id": "uZTNeKWZ8OiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing tokenization\n",
        "nlp = spacy.load(path_model)\n",
        "doc_clean = nlp(text)"
      ],
      "metadata": {
        "id": "_D6laUUP3SUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e6bc41-69ab-4639-ac5c-2f415ebe17f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/spacy/util.py:865: UserWarning: [W095] Model 'es_pipeline' (0.0.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "from pathlib import Path\n",
        "\n",
        "#option visualizers ent\n",
        "colors = {\n",
        "    \"MISC\": \"#808D8E\",\n",
        "    \"LOC\": \"#766C7F\",\n",
        "    \"PERS\": \"#947EB0\",\n",
        "    \"DATE\": \"#A3A5C3\",\n",
        "    \"ORG\": \"#A9D2D5\"\n",
        "    }\n",
        "options= {\"ents\": [\"MISC\", \"LOC\", \"PERS\", \"DATE\", \"ORG\"], \"colors\": colors}\n",
        "\n",
        "#render\n",
        "html = displacy.render(doc_clean, style=\"ent\", jupyter=True, options=options, page=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SqEwX_yg3W6g",
        "outputId": "277146cc-0835-49f4-87a2-b496a8ca98e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
              "<html lang=\"es\">\n",
              "    <head>\n",
              "        <title>displaCy</title>\n",
              "    </head>\n",
              "\n",
              "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
              "<figure style=\"margin-bottom: 6rem\">\n",
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>\n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Comand^oo\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " de armas</br>En este promente recibi la nota de Ue pha. de Aytt.</br>Inmediatamente hire prepio a los \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Anpeles\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              ", participando al Sõr \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Intend^te\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              ", el endito que ha tenido.</br>Tendré mucho cuidado en sufetar todos los \n",
              "<mark class=\"entity\" style=\"background: #808D8E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    animales\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " que Vanien ilegalmente.</br>Jodabia no he recibo do los \n",
              "<mark class=\"entity\" style=\"background: #808D8E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    80 animales\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " que le mande, para hacer la corespondiente débolucion asus dueños</br>Aqui no hai novedad.</br>El conductor D^n Salvador Elmnosilla lleba 25 lanzar, con estas son 124.</br>\n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Naueo Obre\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #A3A5C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    14 de 1859\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".</br>Dios gue. aUd.</br>Jdel \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    C. Dize\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "</br>Al \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Señor Coronel Comand^\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "</br>\n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    U Jefe\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              " dela \n",
              "<mark class=\"entity\" style=\"background: #A9D2D5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Divicion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " pacificadora de \n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Arauco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".</br></br>\n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    --------------------\n",
              "\n",
              "\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "E^te inteime de</br>or el Gobemador del dep^t de Sauteno se me comunica lo que sigue.</br>\n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Santa Juana\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #A3A5C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Conero 2 de 1860\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".</br>Por la \n",
              "<mark class=\"entity\" style=\"background: #A9D2D5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Intend^a\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " demi provincia en nota oficial tha 29 del mes ep^a No N72, seme ordena poner a disporicion de Ud al reo \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Juan\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              " llmorcilla, tetulado \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sarjento\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              " mayor dela montonera de \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Patricio Silva\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "; para que allí sea juegado; i en su concecuencio selo remito bajo segura custodia; i Ud.</br>se servirá acuzarme recibo. Dios que a Us \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Parcual Ruir\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              ".</br>Tolo lo trarcribo a Ul para su conocimiento.</br>Mientras Ud se sirva determinas de dicho reo, he dispueto mandarlo abordo del \n",
              "<mark class=\"entity\" style=\"background: #808D8E; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    vapor\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
              "</mark>\n",
              " Maipú, para la mayor seguridad.</br>\n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Arauco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #A3A5C3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lonezo 2 de 1860\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</br>No 3</br>35</br>1</br>Al Sõr Comand^o en fefe dela \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Piarcion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              " deoperaciones de \n",
              "<mark class=\"entity\" style=\"background: #766C7F; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Arauco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ".</br>Dios gu~e a Ud</br>Jel \n",
              "<mark class=\"entity\" style=\"background: #947EB0; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    C. Diaz\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERS</span>\n",
              "</mark>\n",
              "</br></div>\n",
              "</figure>\n",
              "</body>\n",
              "</html></span>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}